{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f68838-bfaa-413b-865d-6038c2e5f1fd",
   "metadata": {},
   "source": [
    "<center><h1>ğ“œğ“ªğ“»ğ“´ğ“¸ğ“¿ ğ“’ğ“±ğ“ªğ“²ğ“·</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03dd37b-0104-4816-a9a8-26b2b2258f0a",
   "metadata": {},
   "source": [
    "[**Refer This(Wonderful)**](https://www.youtube.com/watch?v=1GKtfgwf3ig)\n",
    "<center><img src=\"https://cdn.buttercms.com/4NJTXOLRRQ2mziK4Qp4z\" width=\"200\".></center>\n",
    "\n",
    "A Markov chain is a random process with the Markov property. A random process or often called stochastic property is a mathematical object defined as a collection of random variables. A Markov chain has either discrete state space (set of possible values of the random variables) or discrete index set (often representing time) - given the fact, many variations for a Markov chain exists. Usually the term \"Markov chain\" is reserved for a process with a discrete set of times, that is a Discrete Time Markov chain (DTMC).\n",
    "\n",
    "`Markov chain don't have memory, if travelling from one state to another, it forget the previous state, so it choose random path to go the next future state`. \n",
    "\n",
    "**Discrete Markov Chain**\n",
    " discrete time Markov chain is a sequence of random variables X1, X2, X3, ... with the Markov property, such that the probability of moving to the next state depends only on the present state and not on the previous states. Putting this is mathematical probabilistic formula:\n",
    "\n",
    "Pr( Xn+1 = x | X1 = x1, X2 = x2, â€¦, Xn = xn) = Pr( Xn+1 = x | Xn = xn)\n",
    "\n",
    "\n",
    "<center><img src=\"https://cdn.buttercms.com/I4B2wnMSAq3jHP9mdsp4\" width=\"800\".></center>\n",
    "\n",
    "**This Graph is called Directed Graph**\n",
    "\n",
    "## Properties: \n",
    "\n",
    "<center><h3>1. ğ¹ğ“Šğ“‰ğ“Šğ“‡ğ‘’ ğ’®ğ“‰ğ’¶ğ“‰ğ‘’ ğ’¹ğ‘’ğ“…ğ‘’ğ“ƒğ’¹ğ“ˆ oğ“ƒğ“ğ“ oğ“ƒ ğ’ğ“Šğ“‡ğ“‡ğ‘’ğ“ƒğ“‰ ğ’®ğ“‰ğ’¶ğ“‰ğ‘’ </h3></center>\n",
    "\n",
    "### $$ P(x n+1 = x | Xn = xn) $$\n",
    "\n",
    "<center><h3>2. ğ’¯ğ’½ğ‘’ ğ“ˆğ“Šğ“‚ ğ‘œğ’» ğ“‰ğ’½ğ‘’ ğ“Œğ‘’ğ’¾ğ‘”ğ’½ğ“‰ğ“ˆ ğ‘œğ’» ğ‘œğ“Šğ“‰ğ‘”ğ‘œğ’¾ğ“ƒğ‘” ğ’¶ğ“‡ğ“‡ğ‘œğ“Œğ“ˆ ğ’»ğ“‡ğ‘œğ“‚ ğ’¶ğ“ƒğ“ ğ“ˆğ“‰ğ’¶ğ“‰ğ‘’ ğ’¾ğ“ˆ ğ‘’ğ“†ğ“Šğ’¶ğ“ ğ“‰ğ‘œ ğŸ£ (ğ’·ğ‘’ğ’¸ğ’¶ğ“Šğ“ˆğ‘’ ğ’¾ğ“‰ ğ’¾ğ“ˆ ğ“…ğ“‡ğ‘œğ’·ğ’¶ğ’·ğ’¾ğ“ğ’¾ğ“‰ğ“) </h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b3afa-dd83-4a18-92a2-917a3f8fadf5",
   "metadata": {},
   "source": [
    "### Transition Probabilities: \n",
    "\n",
    "Consider you need to take a probability of an each event for long events, when you find the probability for any long event you will end up with the **stationary** or **equilibrium state** (it mean your probability values not varies after certain number of caclculations, it remains same). So better way to find the probability of each event is using a **adjacency matrix (A)** it's also called **Transiton matrix (A)**. \n",
    "\n",
    "\n",
    "<center><img src=\"images/trans.png\" width=\"800\".></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f8bdc-3dbb-4b4f-aba7-6f404657ac3c",
   "metadata": {},
   "source": [
    "Markov chains is a statistical process, it's a sequence of events where the probabilities of te future only depend on the present. In simple terms, markov chains don't have memory where it came from, it chooses the future path randomly! \n",
    "\n",
    "\n",
    "<center><img src=\"images/step1.png\" width=\"400\".></center>\n",
    "\n",
    "<center><img src=\"images/step2.png\" width=\"400\".></center>\n",
    "\n",
    "<center><img src=\"images/step3.png\" width=\"400\".></center>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
