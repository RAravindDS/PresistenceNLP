{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31182915-ca4d-4147-9c0d-73fc9aea3ca1",
   "metadata": {},
   "source": [
    "<center><h1>𝒫𝑅𝐸-𝒯𝑅𝒜𝐼𝒩𝐼𝒩𝒢 𝒯𝐸𝒳𝒯 𝐸𝒩𝒞𝒪𝒟𝐸𝑅𝒮\n",
    "𝒜𝒮 𝒟𝐼𝒮𝒞𝑅𝐼𝑀𝐼𝒩𝒜𝒯𝒪𝑅𝒮 𝑅𝒜𝒯𝐻𝐸𝑅 𝒯𝐻𝒜𝒩 𝒢𝐸𝒩𝐸𝑅𝒜𝒯𝒪𝑅𝒮\n",
    "    </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699cc5f-cef1-47c3-9895-c019e0f0cfb9",
   "metadata": {},
   "source": [
    "[*Reserach Paper*](https://arxiv.org/pdf/2003.10555.pdf)\n",
    "\n",
    "**Problem in Masked Language modeling:**\n",
    "* It predicts only a 15% of the token. It only learn the 15% of the data, it don't learn reamining 85% of the data. \n",
    "* Less efficient (it needs more GPU and training power). \n",
    "\n",
    "**How to overcome this?** \n",
    "* Instead of masking and predicting the token we can do the **Replaced Token Detection**.\n",
    "* Instead of masking the input, our approach corrupts it by replacing some tokens with plausible(நம்பத்தகுந்த) alternatives sampled from a small\n",
    "generator network. Then, instead of training a model that predicts the original\n",
    "identities of the corrupted tokens, we train a discriminative model that predicts\n",
    "whether each token in the corrupted input was replaced by a generator sample\n",
    "or not. \n",
    "\n",
    "<center><img src=\"https://1.bp.blogspot.com/-sHybc03nJRo/XmfLongdVYI/AAAAAAAAFbI/a0t5w_zOZ-UtxYaoQlVkmTRsyFJyFddtQCLcBGAsYHQ/s1600/image1.png\" width=\"600\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b33279-0674-474b-9f5c-403b84b9c33c",
   "metadata": {},
   "source": [
    "[**Refer This**](https://www.youtube.com/watch?v=perF6Utzuko&t=12s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636c6240-067e-426e-a486-687500351c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 \n",
    "\n",
    "path = 'C:\\Downloads\\custom\\smilingGirl' \n",
    "\n",
    "im_size = 1024  # square size \n",
    "\n",
    "images = []\n",
    "\n",
    "for file in os.listdir(path): \n",
    "    img = cv2.imread(path + '/' + file)\n",
    "    img = cv2.resize(img, (im_size, im_size)) \n",
    "    images.append(img) \n",
    "    \n",
    "    cv2.imwrite('C:/Downloads/custom/resized_image/' + str(file) + '_resized.jpg', img) \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3fe4b5-c398-404e-ba59-6475736f3dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tf records \n",
    "!pip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
